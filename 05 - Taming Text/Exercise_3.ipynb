{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/user/Desktop/epfl_semester5/data_analyis/anaconda_folder/anaconda/lib/python3.5/site-packages/nltk/twitter/__init__.py:20: UserWarning: The twython library has not been installed. Some functionality from the twitter package will not be available.\n",
      "  warnings.warn(\"The twython library has not been installed. \"\n",
      "/Users/user/Desktop/epfl_semester5/data_analyis/anaconda_folder/anaconda/lib/python3.5/site-packages/gensim/utils.py:1015: UserWarning: Pattern library is not installed, lemmatization won't be available.\n",
      "  warnings.warn(\"Pattern library is not installed, lemmatization won't be available.\")\n"
     ]
    }
   ],
   "source": [
    "from os import path\n",
    "from collections import Counter\n",
    "#import pycountry\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "import re # for removing numbers\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "from gensim import models,corpora\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(path.join('hillary-clinton-emails', 'emails.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'UNCLASSIFIED\\nU.S. Department of State\\nCase No. F-2015-04841\\nDoc No. C05739545\\nDate: 05/13/2015\\nSTATE DEPT. - PRODUCED TO HOUSE SELECT BENGHAZI COMM.\\nSUBJECT TO AGREEMENT ON SENSITIVE INFORMATION & REDACTIONS. NO FOIA WAIVER.\\nRELEASE IN FULL\\nFrom: Sullivan, Jacob J <Sullivan11@state.gov>\\nSent: Wednesday, September 12, 2012 10:16 AM\\nTo:\\nSubject: FW: Wow\\nFrom: Brose, Christian (Armed Services) (mailto:Christian_Brose@armed-servic,essenate.govi\\nSent: Wednesday, September 12, 2012 10:09 AM\\nTo: Sullivan, Jacob J\\nSubject: Wow\\nWhat a wonderful, strong and moving statement by your boss. please tell her how much Sen. McCain appreciated it. Me\\ntoo\\nUNCLASSIFIED\\nU.S. Department of State\\nCase No. F-2015-04841\\nDoc No. C05739545\\nDate: 05/13/2015\\nSTATE DEPT. - PRODUCED TO HOUSE SELECT BENGHAZI COMM.\\nSUBJECT TO AGREEMENT ON SENSITIVE INFORMATION & REDACTIONS. NO FOIA WAIVER. STATE-5CB0045247\\n\\x0c'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['RawText'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "useful_data=df['RawText']\n",
    "type(useful_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "useful_data=df['RawText']# useful_data=df['RawText']\n",
    "#Delete words with numbers\n",
    "without_num = [re.sub(r'\\d+', '', t) for t in useful_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(without_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tokenizer = nltk.tokenize.RegexpTokenizer(r'\\w+')\n",
    "tokennized_text=[tokenizer.tokenize(d) for d in without_num]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Delete words with less than 3 letters and also take care if it is from stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#stopwords\n",
    "sw = set(nltk.corpus.stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tokennized_text=[[s for s in t if (len(s)>2 and s not in sw)] for t in tokennized_text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#convert list of lists to one flattened list for data analysis\n",
    "flattened = []\n",
    "for t in tokennized_text:\n",
    "    for w in t:\n",
    "        flattened.append(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('State', 29830), ('Department', 28674), ('UNCLASSIFIED', 26910), ('Date', 26826), ('Case', 26564), ('Doc', 26539), ('From', 19269), ('Sent', 18847), ('Subject', 18421), ('state', 12797), ('The', 11733), ('gov', 11346), ('RELEASE', 7951), ('Message', 7314), ('Original', 7244), ('com', 6675), ('would', 5684), ('Huma', 5681), ('said', 5579), ('Cheryl', 5531), ('Abedin', 5191), ('clintonemail', 4995), ('Mills', 4763), ('PART', 4347), ('Secretary', 4005), ('Sullivan', 3908), ('call', 3824), ('FULL', 3588), ('Obama', 3548), ('Jacob', 3463), ('also', 3452), ('one', 3442), ('time', 3370), ('government', 3251), ('Clinton', 3088), ('President', 3022), ('people', 2969), ('new', 2863), ('This', 2813), ('know', 2783), ('HDR', 2764), ('STATE', 2646), ('work', 2579), ('like', 2532), ('But', 2525), ('get', 2504), ('could', 2480), ('United', 2428), ('AbedinH', 2382), ('American', 2379), ('security', 2342), ('http', 2285), ('two', 2218), ('May', 2165), ('Friday', 2129), ('And', 2091), ('Thursday', 2075), ('support', 2064), ('Haiti', 2062), ('see', 2044), ('need', 2042), ('Sunday', 2039), ('Monday', 2033), ('well', 2025), ('States', 2016), ('today', 2014), ('MillsCD', 2000), ('Tuesday', 1976), ('last', 1959), ('Wednesday', 1951), ('hrod', 1950), ('September', 1927), ('think', 1916), ('first', 1898), ('want', 1844), ('SENSITIVE', 1823), ('Israel', 1806), ('back', 1806), ('world', 1805), ('country', 1774), ('policy', 1767), ('make', 1765), ('political', 1753), ('www', 1743), ('foreign', 1742), ('meeting', 1725), ('INFORMATION', 1725), ('SUBJECT', 1723), ('HOUSE', 1720), ('Saturday', 1707), ('BENGHAZI', 1705), ('Washington', 1703), ('FOIA', 1702), ('DEPT', 1700), ('AGREEMENT', 1698), ('COMM', 1696), ('WAIVER', 1696), ('REDACTIONS', 1696), ('PRODUCED', 1696), ('SELECT', 1696), ('week', 1684), ('House', 1675), ('They', 1648), ('year', 1636), ('may', 1634), ('much', 1625), ('told', 1615), ('way', 1603), ('good', 1602), ('years', 1591), ('many', 1590), ('August', 1589), ('public', 1583), ('Office', 1573), ('Minister', 1532), ('made', 1515), ('going', 1487), ('military', 1482), ('October', 1479), ('tomorrow', 1468), ('help', 1467), ('even', 1459), ('right', 1457), ('Sun', 1457), ('David', 1441), ('December', 1439), ('June', 1436), ('November', 1435), ('Sat', 1426), ('take', 1425), ('New', 1420), ('president', 1402), ('next', 1393), ('January', 1387), ('say', 1375), ('former', 1321), ('Hillary', 1319), ('Aug', 1313), ('Afghanistan', 1306), ('long', 1306), ('including', 1293), ('working', 1287), ('Iran', 1276), ('talk', 1275), ('speech', 1270), ('still', 1261), ('Pakistan', 1249), ('deal', 1243), ('There', 1235), ('countries', 1233), ('women', 1224), ('April', 1221), ('administration', 1213), ('email', 1210), ('China', 1208), ('Libya', 1199), ('report', 1187), ('day', 1183), ('called', 1179), ('issues', 1174), ('leaders', 1168), ('come', 1166), ('office', 1153), ('mailto', 1148), ('You', 1147), ('White', 1142), ('For', 1130), ('officials', 1122), ('international', 1122), ('March', 1103), ('Fri', 1095), ('says', 1093), ('Sid', 1090), ('July', 1087), ('That', 1084), ('Thu', 1084), ('asked', 1083), ('What', 1077), ('power', 1073), ('must', 1070), ('Lauren', 1067), ('Wed', 1062), ('issue', 1055), ('peace', 1054), ('America', 1047), ('efforts', 1038), ('Senate', 1037), ('part', 1036), ('best', 1036), ('around', 1032), ('morning', 1032), ('Israeli', 1029), ('She', 1029), ('since', 1018), ('Foreign', 1009), ('development', 1007), ('message', 1006), ('election', 997), ('Dec', 996), ('end', 991)]\n"
     ]
    }
   ],
   "source": [
    "# now check words with highest frequency to see whether some of the words arent from email content \n",
    "from collections import Counter\n",
    "counts = Counter(flattened)\n",
    "#print most common words\n",
    "print(counts.most_common(200))\n",
    "#now delete words with highest frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# by checking the counts with corresponding words we can see that top 15 words arent useful for our purposes\n",
    "highest_frequency=counts.most_common(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Delete words that appear in more than 90% of the documents. These words are coming from email headers that doesn't represent the email content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "unuseful_words=[]\n",
    "for i in range(0,len(highest_frequency)):\n",
    "    unuseful_words.append(highest_frequency[i][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['State',\n",
       " 'Department',\n",
       " 'UNCLASSIFIED',\n",
       " 'Date',\n",
       " 'Case',\n",
       " 'Doc',\n",
       " 'From',\n",
       " 'Sent',\n",
       " 'Subject',\n",
       " 'state',\n",
       " 'The',\n",
       " 'gov',\n",
       " 'RELEASE',\n",
       " 'Message',\n",
       " 'Original']"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unuseful_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Update tokenized text\n",
    "tokennized_text_n=[[s for s in t if s not in unuseful_words] for t in tokennized_text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.010*\"Secretary\" + 0.007*\"Office\" + 0.003*\"Room\" + 0.003*\"com\" + 0.003*\"would\" + 0.003*\"MEETING\" + 0.003*\"Clinton\" + 0.003*\"route\" + 0.003*\"PART\" + 0.003*\"ARRIVE\"'),\n",
       " (1,\n",
       "  '0.005*\"said\" + 0.005*\"would\" + 0.004*\"Obama\" + 0.003*\"government\" + 0.003*\"Israel\" + 0.003*\"one\" + 0.003*\"American\" + 0.003*\"But\" + 0.003*\"people\" + 0.003*\"http\"'),\n",
       " (2,\n",
       "  '0.015*\"com\" + 0.012*\"Huma\" + 0.012*\"clintonemail\" + 0.011*\"Abedin\" + 0.009*\"PART\" + 0.008*\"call\" + 0.007*\"HDR\" + 0.005*\"AbedinH\" + 0.004*\"hrod\" + 0.004*\"FULL\"'),\n",
       " (3,\n",
       "  '0.012*\"Cheryl\" + 0.011*\"Mills\" + 0.009*\"Sullivan\" + 0.009*\"Jacob\" + 0.005*\"com\" + 0.005*\"FULL\" + 0.005*\"Huma\" + 0.005*\"clintonemail\" + 0.005*\"Secretary\" + 0.004*\"PART\"'),\n",
       " (4,\n",
       "  '0.006*\"said\" + 0.006*\"Huma\" + 0.005*\"Abedin\" + 0.005*\"com\" + 0.004*\"AbedinH\" + 0.004*\"NEWS\" + 0.004*\"FULL\" + 0.003*\"call\" + 0.003*\"Reuters\" + 0.003*\"people\"')]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dictionary = corpora.Dictionary(tokennized_text_n)\n",
    "corpus = [dictionary.doc2bow(t) for t in tokennized_text_n]\n",
    "lda=models.LdaModel(corpus, num_topics=5,id2word=dictionary)\n",
    "lda.print_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
